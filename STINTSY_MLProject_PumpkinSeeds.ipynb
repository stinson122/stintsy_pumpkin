{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STINTSY Machine Learning Project: Pumpkin Seeds Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STINTSY S11 - Milky Way** \\\n",
    "*Group Members:*\n",
    "- Gutierrez, Mark Daniel\n",
    "- Refuerzo, Lloyd Dominic\n",
    "- Romblon, Kathleen Mae\n",
    "- Stinson, Audrey Lauren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1** | **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pumpkin plant belongs to the Cucurbitaceae family and has seasonal varieties. Confectionery pumpkins, grown in Turkey, are usually produced from the pumpkin species, *Cucurbita pepo* L and sometimes from the *Cucurbita moschata* Duchesne type. Pumpkin seeds are considered as important for human health because it contains 37 percent of carbohydrate, 35 percent to 40 percent of fat and protein along with calcium, potassium, phosphorus, magnesium, iron, and zinc. Pumpkins are divided into many types, and one of these species is known as “Urgup Sivrisi”. Urgup Sivrisi is a type of pumpkin seed that has a long, white, very bright, thin, and hardly distinguishable shell with a pointed tip. The other type of pumpkin seeds is “Cercevelik”. It is a particular species grown in Turkey, Nevsehir, Karacaoren, and known as “Topak” in Turkey. <span style=\"color:#42adf5\">(*taken directly from* Details *section of the Pumpkin Seeds Dataset pdf*)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target task for this dataset is to correctly classify whether an image of a pumpkin seed is of the species type \"Urgup Sivrisi\" or \"Cercevelik\". The dataset then offers a <span style=\"color:#f5b942\">classification problem</span> that the group will address through the use of various machine learning models, namely **k-Nearest Neighbors**, **Decision Trees**, and **Logistic Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2** | **About the Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset, collected by Koklu et al. (2021), contains extracted features from 2500 images of two varieties of pumpkin seeds, Urgup Sivrisi and Cercevelik. These images were taken inside a product shooting box to prevent shadows from showing if light from outside of the box were to get in. To process the original RGB images, they were converted to gray-toned images, and then to binary images to simplify the value of each pixel in the image. As the RGB images will be converted to binary images for the image processing part, the shadows can make the acquired size and shape of the seed appear smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the image binarization of each of the 2500 images, 12 features were extracted for each instance. The extracted features are based on the shape of the pumpkin seeds, where each pixel in the image was calculated while considering the values of other nearby pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, the extracted features are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <span style=\"color:#f5b942\">Area:</span> Number of pixels within the borders of a pumpkin seed\n",
    "2. <span style=\"color:#f5b942\">Perimeter:</span> Circumference in pixels of a pumpkin seed\n",
    "3. <span style=\"color:#f5b942\">Major Axis Length:</span> Large axis distance of a pumpkin seed\n",
    "4. <span style=\"color:#f5b942\">Minor Axis Length:</span> Small axis distance of a pumpkin seed\n",
    "5. <span style=\"color:#f5b942\">Convex Area:</span> Number of pixels of the smallest convex shell at the region formed by the pumpkin seed\n",
    "6. <span style=\"color:#f5b942\">Equiv Diameter:</span> Computed as $\\sqrt{4a/\\pi}$, where $a$ is the area of the pumpkin seed\n",
    "7. <span style=\"color:#f5b942\">Eccentricity:</span> Eccentricity of a pumpkin seed\n",
    "8. <span style=\"color:#f5b942\">Solidity:</span> Convex condition of the pumpkin seeds\n",
    "9. <span style=\"color:#f5b942\">Extent:</span> Ratio of a pumpkin seed area to the bounding box pixels\n",
    "10. <span style=\"color:#f5b942\">Roundness:</span> Ovality of pumpkin seeds without considering the distortion of the edges\n",
    "11. <span style=\"color:#f5b942\">Aspect Ratio:</span> Aspect ratio of the pumpkin seeds\n",
    "12. <span style=\"color:#f5b942\">Compactness:</span> Proportion of the area of the pumpkin seed relative to the area of the circle with the same circumference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3** | **List of Requirements**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell imports the libraries needed for setting up the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4** | **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Importing the dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following cell, we will be using the `read_csv` function to import the pumpkin seeds dataset to our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pumpkin_seeds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we have imported the data, we can take a look at the first and last 10 instances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (no. of instances, no. of columns [features + target label])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 13 columns, where the first 12 columns are the input features and the last column is the target label. There are 2500 instances in total, and the shape of the dataset is `(2500, 13)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can see the statistical summary of the dataset by calling the `describe()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Data Cleaning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, one of the features, `Aspect_Ration`, is spelled incorrectly. To fix this, we will rename that column to `Aspect_Ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming and reformatting the features\n",
    "data.columns = ['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Convex_Area', 'Equiv_Diameter',\n",
    "                'Eccentricity', 'Solidity', 'Extent', 'Roundness', 'Aspect_Ratio', 'Compactness', 'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class labels can be renamed so that it only includes letters from the English alphabet, and this will be done by running the following cell block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class'] = data['Class'].str.strip().str.title().replace({'Çerçevelik': 'Cercevelik'})\n",
    "data['Class'] = data['Class'].str.strip().str.title().replace({'Ürgüp Sivrisi': 'Urgup Sivrisi'})\n",
    "#data.info()\n",
    "#data.hist(figsize=(12,12))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In continuation, we can check if there are other representations of the Class column by calling the `unique()` function on it. Since there are only two unique values, we do not need to make any changes for this column for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `info()` function, we can check any feature with incorrect datatype. If there are inconsistencies with the datatype, it is likely to be assigned an `object` datatype. It should also be noted that for features that we would usually assume to have a `string` datatype, it is possible that they have `object` datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one of these features have the `object` datatype assigned to it, which is the `Class` column. However, since we have already queried its unique values in the previous section, we know that there shouldn't be inconsistencies in this column, so we can keep this column as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to check if there are any missing values or instances where a default value has been assigned. In a pandas dataframe, these are usually represented as `None` or `NaN`, so we can query for any null values in our dataset. Additionally, we can also check if there are any duplicated instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.isnull().sum())\n",
    "display(data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished checking the data, we can now split the data into features (`X`) and the target label (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split features and label\n",
    "X = data.drop(columns=['Class','Convex_Area','Equiv_Diameter']).values\n",
    "y = data['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some models may require that our features are normalized, so we'll define a normalized X variable using the `MinMaxScaler` library's `fit_transform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "scaler = MinMaxScaler()\n",
    "X_norm = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our class labels can be represented numerically. To do this, we use the `LabelEncoder` library's `fit_transform()` function on our target label `y` to represent **Cercevelik** as class `0` and **Urgup Sivrisi** as class `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Cercevelik as 0, Urgup Sivrisi as 1\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "#Check if y is properly transformed\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for the purposes of our exploratory data analysis, we will also transform the `Class` column in our dataframe so that **Cercevelik** is represented as `0` and **Urgup Sivrisi** is represented as class `1`. We will be doing this in a temporary dataframe so as not to affect the original dataframe with the named labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = data\n",
    "\n",
    "# temp_df['Class'] = label_encoder.fit_transform(temp_df['Class'])\n",
    "\n",
    "temp_df['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5** | **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some things that we can take into consideration when trying to classify a pumpkin seed. As this is a dataset that contains morphological features of the two specific species of pumpkin seeds, we can explore the features that represent the size and the shape of the seed. Some of the EDA questions that we have come up with are listed in the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*General:*\n",
    "- How much of the data are Cercevelik pumpkin seeds and Urgup Sivrisi pumpkin seeds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Size:*\n",
    "- What are the features of the seed that has the smallest perimeter? The largest?\n",
    "    - What is the average perimeter of each of the pumpkin seeds?\n",
    "- What are the features of the most narrow seed of each pumpkin seed? The widest?\n",
    "    - What is the average width of each of the pumpkin seeds?\n",
    "- What are the features of the shortest seed of each pumpkin seed? The longest?\n",
    "    - What is the average length of each of the pumpkin seeds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shape:*\n",
    "- What are the features of the most circular seed for each of the pumpkin seed species? The most elongated?\n",
    "    - What is the average eccentricity of each of the pumpkin seed species?\n",
    "- What are the features of the least round seed for each of the pumpkin seed species? The most round?\n",
    "    - What is the average roundness of each of the pumpkin seed species?\n",
    "- <span style=\"color:red\">Convex area</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much of the data are Cercevelik pumpkin seeds and Urgup Sivrisi pumpkin seeds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the count of each of the pumpkin seed species in the dataset, we can group our dataset by `Class` and call the `size()` function on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of each pumpkin seed\n",
    "seed_counts = temp_df.groupby('Class').size()\n",
    "\n",
    "seed_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are 1300 Cercevelik pumpkin seeds and 1200 Urgup Sivrisi pumpkin seeds in the dataset. Since we have grouped our dataset by `Class`, we can assign these groups to their own variables so that we can further explore our data. We would also need to reset the index so that both of the new dataframes start at index `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group according to class (Cercevelik or Urgup Sivrisi)\n",
    "groups = temp_df.groupby('Class')\n",
    "\n",
    "# Assign to their own variables to check in further EDA questions\n",
    "cercevelik_seeds, urgup_seeds = groups.get_group(\"Cercevelik\"), groups.get_group(\"Urgup Sivrisi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index for Cercevelik\n",
    "cercevelik_seeds = cercevelik_seeds.reset_index()\n",
    "\n",
    "# Drop index column\n",
    "cercevelik_seeds.drop(columns=\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index for Urgup Sivrisi\n",
    "urgup_seeds = urgup_seeds.reset_index()\n",
    "\n",
    "# Drop index column\n",
    "urgup_seeds.drop(columns=\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the new dataframes in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cercevelik_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urgup_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows how many seeds there are in each of the species in graph form, and compares them side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=temp_df,x='Class',kind='count')\n",
    "g.set_axis_labels(\"\", \"Number of seeds\")\n",
    "g.set_xticklabels([\"Cercevelik\", \"Urgup Sivrisi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following few questions are questions created for probing on the **Size** of the seeds. The features that we think are relevant to learning about the difference in size between the two pumpkin seed species are `Perimeter`, `Minor Axis Length`, and `Major Axis Length`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the features of the seed that has the smallest perimeter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik min perimeter\n",
    "cercevelik_perim_min = cercevelik_seeds['Perimeter'].min()\n",
    "# Index\n",
    "cercevelik_perim_min_idx = cercevelik_seeds['Perimeter'].idxmin()\n",
    "\n",
    "print(\"Cercevelik seed with smallest perimeter =\", cercevelik_perim_min) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_perim_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup sivrisi min perimeter\n",
    "urgup_perim_min = urgup_seeds['Perimeter'].min()\n",
    "# Index\n",
    "urgup_perim_min_idx = urgup_seeds['Perimeter'].idxmin()\n",
    "\n",
    "print(\"Urgup Sivrisi seed with smallest perimeter =\", urgup_perim_min) # Value\n",
    "urgup_seeds.iloc[[urgup_perim_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The largest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik max perimeter\n",
    "cercevelik_perim_max = cercevelik_seeds['Perimeter'].max()\n",
    "# Index\n",
    "cercevelik_perim_max_idx = cercevelik_seeds['Perimeter'].idxmax()\n",
    "\n",
    "print(\"Cercevelik seed with largest perimeter =\", cercevelik_perim_max) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_perim_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup sivrisi max perimeter\n",
    "urgup_perim_max = urgup_seeds['Perimeter'].max()\n",
    "# Index\n",
    "urgup_perim_max_idx = urgup_seeds['Perimeter'].idxmax()\n",
    "\n",
    "print(\"Urgup Sivrisi seed with largest perimeter =\", urgup_perim_max) # Value\n",
    "urgup_seeds.iloc[[urgup_perim_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average perimeter of each of the pumpkin seeds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cercevelik_perim_avg = cercevelik_seeds['Perimeter'].mean()\n",
    "\n",
    "print(\"Cercevelik seed average perimeter =\", cercevelik_perim_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urgup_perim_avg = urgup_seeds['Perimeter'].mean()\n",
    "\n",
    "print(\"Urgup Sivrisi seed average perimeter =\", urgup_perim_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the features of the most narrow seed of each pumpkin seed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik min minor axis\n",
    "cercevelik_miax_min = cercevelik_seeds['Minor_Axis_Length'].min()\n",
    "# Index\n",
    "cercevelik_miax_min_idx = cercevelik_seeds['Minor_Axis_Length'].idxmin()\n",
    "\n",
    "print(\"Value of most narrow Cercevelik seed =\", cercevelik_miax_min) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_miax_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup sivrisi min minor axis\n",
    "urgup_miax_min = urgup_seeds['Minor_Axis_Length'].min()\n",
    "# Index\n",
    "urgup_miax_min_idx = urgup_seeds['Minor_Axis_Length'].idxmin()\n",
    "\n",
    "print(\"Value of most narrow Urgup Sivrisi seed =\", urgup_miax_min) # Value\n",
    "urgup_seeds.iloc[[urgup_miax_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The widest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik max minor axis\n",
    "cercevelik_miax_max = cercevelik_seeds['Minor_Axis_Length'].max()\n",
    "# Index\n",
    "cercevelik_miax_max_idx = cercevelik_seeds['Minor_Axis_Length'].idxmax()\n",
    "\n",
    "print(\"Value of widest Cercevelik seed =\", cercevelik_miax_max) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_miax_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup sivrisi max minor axis\n",
    "urgup_miax_max = urgup_seeds['Minor_Axis_Length'].max()\n",
    "# Index\n",
    "urgup_miax_max_idx = urgup_seeds['Minor_Axis_Length'].idxmax()\n",
    "\n",
    "print(\"Value of widest Urgup Sivrisi seed =\", urgup_miax_max) # Value\n",
    "urgup_seeds.iloc[[urgup_miax_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average width of each of the pumpkin seeds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cercevelik_miax_avg = cercevelik_seeds['Minor_Axis_Length'].mean()\n",
    "\n",
    "print(\"Cercevelik seed average Minor Axis Length or Width =\", cercevelik_miax_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urgup_miax_avg = urgup_seeds['Minor_Axis_Length'].mean()\n",
    "\n",
    "print(\"Urgup Sivrisi seed average Minor Axis Length or Width =\", urgup_miax_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the features of the shortest seed of each pumpkin seed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik min major axis\n",
    "cercevelik_majax_min = cercevelik_seeds['Major_Axis_Length'].min()\n",
    "# Index\n",
    "cercevelik_majax_min_idx = cercevelik_seeds['Major_Axis_Length'].idxmin()\n",
    "\n",
    "print(\"Value of shortest Cercevelik seed =\", cercevelik_majax_min) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_majax_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup Sivrisi min major axis\n",
    "urgup_majax_min = urgup_seeds['Major_Axis_Length'].min()\n",
    "# Index\n",
    "urgup_majax_min_idx = urgup_seeds['Major_Axis_Length'].idxmin()\n",
    "\n",
    "print(\"Value of shortest Urgup Sivrisi seed =\", urgup_majax_min) # Value\n",
    "urgup_seeds.iloc[[urgup_majax_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The longest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik max major axis\n",
    "cercevelik_majax_max = cercevelik_seeds['Major_Axis_Length'].max()\n",
    "# Index\n",
    "cercevelik_majax_max_idx = cercevelik_seeds['Major_Axis_Length'].idxmax()\n",
    "\n",
    "print(\"Value of longest Cercevelik seed =\", cercevelik_majax_max) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_majax_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup Sivrisi max major axis\n",
    "urgup_majax_max = urgup_seeds['Major_Axis_Length'].max()\n",
    "# Index\n",
    "urgup_majax_max_idx = urgup_seeds['Major_Axis_Length'].idxmax()\n",
    "\n",
    "print(\"Value of longest Urgup Sivrisi seed =\", urgup_majax_max) # Value\n",
    "urgup_seeds.iloc[[urgup_majax_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average length of each of the pumpkin seeds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cercevelik_majax_avg = cercevelik_seeds['Major_Axis_Length'].mean()\n",
    "\n",
    "print(\"Cercevelik seed average Major Axis Length or Length =\", cercevelik_majax_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urgup_majax_avg = urgup_seeds['Major_Axis_Length'].mean()\n",
    "\n",
    "print(\"Urgup Sivrisi seed average Major Axis Length or Length =\", urgup_majax_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following few questions are questions created for probing on the *Shape** of the seeds. The features that we think are relevant to learning about the difference in shape between the two pumpkin seed species are `Eccentricity`, `Roundness`, and `Convex Area`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the features of the most circular seed for each of the pumpkin seed species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik min eccentricity\n",
    "cercevelik_ecce_min = cercevelik_seeds['Eccentricity'].min()\n",
    "# Index\n",
    "cercevelik_ecce_min_idx = cercevelik_seeds['Eccentricity'].idxmin()\n",
    "\n",
    "print(\"Value of most circular Cercevelik seed =\", cercevelik_ecce_min) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_ecce_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup sivrisi min eccentricity\n",
    "urgup_ecce_min = urgup_seeds['Eccentricity'].min()\n",
    "# Index\n",
    "urgup_ecce_min_idx = urgup_seeds['Eccentricity'].idxmin()\n",
    "\n",
    "print(\"Value of most circular Urgup Sivrisi seed =\", urgup_ecce_min) # Value\n",
    "urgup_seeds.iloc[[urgup_ecce_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most elongated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik max eccentricity\n",
    "cercevelik_ecce_max = cercevelik_seeds['Eccentricity'].max()\n",
    "# Index\n",
    "cercevelik_ecce_max_idx = cercevelik_seeds['Eccentricity'].idxmax()\n",
    "\n",
    "print(\"Value of most elongated Cercevelik seed =\", cercevelik_ecce_max) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_ecce_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup sivrisi max eccentricity\n",
    "urgup_ecce_max = urgup_seeds['Eccentricity'].max()\n",
    "# Index\n",
    "urgup_ecce_max_idx = urgup_seeds['Eccentricity'].idxmax()\n",
    "\n",
    "print(\"Value of most elongated Urgup Sivrisi seed =\", urgup_ecce_max) # Value\n",
    "urgup_seeds.iloc[[urgup_ecce_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average eccentricity of each of the pumpkin seed species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cercevelik_ecce_avg = cercevelik_seeds['Eccentricity'].mean()\n",
    "\n",
    "print(\"Cercevelik seed average eccentricity =\", cercevelik_ecce_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urgup_ecce_avg = urgup_seeds['Eccentricity'].mean()\n",
    "\n",
    "print(\"Urgup Sivrisi seed average eccentricity =\", urgup_ecce_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the features of the least round seed for each of the pumpkin seed species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik min roundness\n",
    "cercevelik_round_min = cercevelik_seeds['Roundness'].min()\n",
    "# Index\n",
    "cercevelik_round_min_idx = cercevelik_seeds['Roundness'].idxmin()\n",
    "\n",
    "print(\"Value of least round Cercevelik seed =\", cercevelik_round_min) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_round_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup sivrisi min roundness\n",
    "urgup_round_min = urgup_seeds['Roundness'].min()\n",
    "# Index\n",
    "urgup_round_min_idx = urgup_seeds['Roundness'].idxmin()\n",
    "\n",
    "print(\"Value of least round Urgup Sivrisi seed =\", urgup_round_min) # Value\n",
    "urgup_seeds.iloc[[urgup_round_min_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most round?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cercevelik max roundness\n",
    "cercevelik_round_max = cercevelik_seeds['Roundness'].max()\n",
    "# Index\n",
    "cercevelik_round_max_idx = cercevelik_seeds['Roundness'].idxmax()\n",
    "\n",
    "print(\"Value of least round Cercevelik seed =\", cercevelik_round_max) # Value\n",
    "cercevelik_seeds.iloc[[cercevelik_round_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgup sivrisi max roundness\n",
    "urgup_round_max = urgup_seeds['Roundness'].max()\n",
    "# Index\n",
    "urgup_round_max_idx = urgup_seeds['Roundness'].idxmax()\n",
    "\n",
    "print(\"Value of least round Urgup Sivrisi seed =\", urgup_round_max) # Value\n",
    "urgup_seeds.iloc[[urgup_round_max_idx]] # Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average roundness of each of the pumpkin seed species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cercevelik_round_avg = cercevelik_seeds['Roundness'].mean()\n",
    "\n",
    "print(\"Cercevelik seed average roundness =\", cercevelik_round_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urgup_round_avg = urgup_seeds['Roundness'].mean()\n",
    "\n",
    "print(\"Urgup Sivrisi seed average roundness =\", urgup_round_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=========================================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s play around with the data and find association among them. First, we check the correlation between features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df['Class'] = label_encoder.fit_transform(temp_df['Class'])\n",
    "# temp_df.corr()['Class'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the four features which have strongest relationship with Class are <b>Aspect_Ratio, Eccentricity, Major_Axis_Length and Perimeter</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we display the correlations of each combination of two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = temp_df.corr().round(2)\n",
    "# sns.heatmap(corr,cmap=\"rocket\",annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brighter the color is, the stronger the relationship between 2 variables.<br>\n",
    "Notably, 3 features have perfect positive correlation with each other: `Area`, `Convex_Area` and `Equiv_Diameter`. Since these features have almost the same correlations with `Class`, these features could be dropped from the training dataset.<br>\n",
    "Other closely correlated features are `Aspect_Ratio` and `Eccentricity` with $0.95$ correlation, then `Perimeter` with `Area`, `Convex_Area` and `Equiv_Diameter` with $0.93$ correlation. Meanwhile, `Compactness` and `Aspect_Ratio` are highly inversely correlated at $-0.99$ correlation, implying `Compactness` decreases with increasing `Aspect_Ratio`.\n",
    "\n",
    "Let’s plot some interesting pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of data in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.catplot(data=temp_df,x='Class',kind='count')\n",
    "# g.set_axis_labels(\"\", \"Number of seeds\")\n",
    "# g.set_xticklabels([\"Cercevelik\", \"Urgup Sivrisi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in the dataset, the number of instances classified as Çerçevelik seeds is slightly more than that of Ürgüp Sivrisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the relationship between Class and the first four features which have strongest relationship with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Boxplot\n",
    "# f = plt.figure(figsize=(12,8))\n",
    "\n",
    "# plt.subplot(2,2,1)\n",
    "# # Aspect_Ration vs Class\n",
    "# a=sns.boxplot(data=temp_df,x='Class',y='Aspect_Ratio')\n",
    "# a.set_xticklabels([\"Cercevelik\", \"Urgup Sivrisi\"])\n",
    "\n",
    "# plt.subplot(2,2,2)\n",
    "# # Eccentricity vs Class\n",
    "# b=sns.boxplot(data=temp_df,x='Class',y='Eccentricity')\n",
    "# b.set_xticklabels([\"Cercevelik\", \"Urgup Sivrisi\"])\n",
    "\n",
    "# plt.subplot(2,2,3)\n",
    "# # Major_Axis_Length vs Class\n",
    "# c=sns.boxplot(data=temp_df,x='Class',y='Major_Axis_Length')\n",
    "# c.set_xticklabels([\"Cercevelik\", \"Urgup Sivrisi\"])\n",
    "\n",
    "# plt.subplot(2,2,4)\n",
    "# # Perimeter vs Class\n",
    "# d=sns.boxplot(data=temp_df,x='Class',y='Perimeter')\n",
    "# d.set_xticklabels([\"Cercevelik\", \"Urgup Sivrisi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ürgüp Sivrisi has a higher median in all 4 features. Since these features are related to shape and size, this may imply that Ürgüp Sivrisi seeds are generally bigger and more elongated than Çerçevelik seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the correlation plot, some other combinations of the variables also show strong relationships (around 0.95). Let’s have a look at the four of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #The relationships among other features\n",
    "# f = plt.figure(figsize=(16,12))\n",
    "# #Roundness vs. Compactness\n",
    "# plt.subplot(2,2,1)\n",
    "# sns.scatterplot(data=temp_df,x='Compactness', y='Roundness',hue='Class')\n",
    "# plt.grid()\n",
    "\n",
    "# #Perimeter vs. Major_Axis_Length\n",
    "# plt.subplot(2,2,2)\n",
    "# sns.scatterplot(data=temp_df,x='Perimeter', y='Major_Axis_Length',hue='Class')\n",
    "# plt.grid()\n",
    "\n",
    "# #Perimeter vs. Area\n",
    "# plt.subplot(2,2,3)\n",
    "# sns.scatterplot(data=temp_df,x='Perimeter', y='Area',hue='Class')\n",
    "# plt.grid()\n",
    "\n",
    "# #Perimeter vs. Convex_Area\n",
    "# plt.subplot(2,2,4)\n",
    "# sns.scatterplot(data=temp_df,x='Perimeter', y='Convex_Area',hue='Class')\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot is divided according to their class. As you can see two features got very strong relationships. While they don’t have strong relationships with **Class**, which can be seen from the distribution of orange and blue points, representing two different seed classes. The distribution of two classes doesn’t appear like cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6** | **Initial Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 1: K-Nearest Neighbors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as the data is normalized and scaled properly, KNN can work well with numerical features. It's also faster with smaller data since it just \"memorizes\" the training set. Using k-fold cross-validation, the model can evaluate predictions with training data alone, by splitting it to smaller subsets. (3.1. Cross-validation: Evaluating Estimator Performance, n.d.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Setting up Libraries and Datasets</b>\n",
    "\n",
    "First, we import the needed libraries for KNN model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score # Evaluation metrics for later analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the data to training set (70%) and testing set (30%). The training set will be used to train the model while the testing set will be used for evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=1)\n",
    "print(\"Training Features (X_train):\\n\", X_train)\n",
    "print(\"Training Labels (y_train):\\n\", y_train)\n",
    "print(\"Testing Features (X_test):\\n\", X_test)\n",
    "print(\"Testing Labels (y_test):\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hyperparameter Tuning with Cross-Validation</b>\n",
    "\n",
    "In training the model, we'll need to find a good value for the hyperparameter `k`, the number of neighbors.\n",
    "We'll test values from 1-20 and get the average cross-validation accuracy of the model on each `k`. The accuracy will be stored in `accuracy_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_choices = range(1, 21)\n",
    "accuracy_scores = []\n",
    "for k in k_choices:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k) # Instantiate\n",
    "    score = cross_val_score(knn, X_train, y_train, cv=10).mean() # Get the avg cross-val accuracy\n",
    "    accuracy_scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the accuracy scores of each k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(accuracy_scores)):\n",
    "    plt.scatter(k_choices[i], accuracy_scores[i])\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Cross-validation accuracy\")\n",
    "plt.title(\"Cross-validation on k\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best `k` seems to be between $12.5$ and $15.0$, with a cross-validation accuracy higher than 0.87. Now let's compute this based on the accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = k_choices[np.argmax(accuracy_scores)]\n",
    "print(\"Best k:\", best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model using the best `k` ($14$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_k) # Instantiate with best k\n",
    "knn.fit(X_train, y_train) # Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 2: Decision Tree*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries needed for decision tree classifier -> **TO MOVE TO SECTION 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have a classification problem in our hands, we will be using the `DecisionTreeClassifier` library from `sklearn` for training our decision tree model on the pumpkin seeds dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">why decision tree?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we will be splitting our train (70%) and test (30%) data. It is enough to use the original, non-normalized data for decision trees as normalization does not affect the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*On data normalization:* <br> https://forecastegy.com/posts/do-decision-trees-need-feature-scaling-or-normalization/ <br>\n",
    "https://sebastianraschka.com/faq/docs/when-to-standardize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_X_train, dt_X_test, dt_y_train, dt_y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "# print(\"X train: \\n\" + str(X_train))\n",
    "# print(\"y train: \\n\" + str(y_train))\n",
    "# print(\"X test: \\n\" + str(X_test))\n",
    "# print(\"y test: \\n\" + str(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape : \", dt_X_train.shape)\n",
    "print(\"y_train shape : \", dt_y_train.shape)\n",
    "print(\"X_test shape : \", dt_X_test.shape)\n",
    "print(\"y_test shape : \", dt_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting, we end up with training data that has 1750 instances and test data with 750 instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the decision tree modeling, we will be using the default parameters for the `DecisionTreeClassifier` to see its baseline performance. In the following cell, we will be defining our decision tree as `pumpkin_dt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be fitting the decision tree model on the training data and creating predictions on the test data in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "pumpkin_dt.fit(dt_X_train, dt_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "pumpkin_dt_test_preds = pumpkin_dt.predict(dt_X_test)\n",
    "pumpkin_dt_test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the decision tree model and created predictions on our test data, we can describe and visualize our tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the definition of the function for describing the decisiont tree. The tree structure description is taken from this page in scikit-learn: <br> https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_tree(clf):\n",
    "    n_nodes = clf.tree_.node_count\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    feature = clf.tree_.feature\n",
    "    threshold = clf.tree_.threshold\n",
    "    values = clf.tree_.value\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    print(\n",
    "        \"The binary tree structure has {n} nodes and has \"\n",
    "        \"the following tree structure:\\n\".format(n=n_nodes)\n",
    "    )\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            print(\n",
    "                \"{space}node={node} is a leaf node, values: {values}.\".format(\n",
    "                    space=node_depth[i] * \"\\t\", node=i, values=values[i]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"{space}node={node} is a split node: \"\n",
    "                \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "                \"else to node {right}.\".format(\n",
    "                    space=node_depth[i] * \"\\t\",\n",
    "                    node=i,\n",
    "                    left=children_left[i],\n",
    "                    feature=feature[i],\n",
    "                    threshold=threshold[i],\n",
    "                    right=children_right[i],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_tree(pumpkin_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ended up getting a tree structure for our test data that has 367 nodes in total. At the root node, it looks at the feature at index 6 to ask the first question, and this feature is the `Eccentricity` of the pumpkin seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot our tree as a graph by calling the `plot_tree` function from `sklearn.tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(pumpkin_dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the confusion matrix, classification report, and the test accuracy for the tree now that we have visualized it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix of the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(dt_y_test, pumpkin_dt_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Çerçevelik is encoded as 0 and Ürgüp Sivrisi as 1. The confusion matrix resulted in the following values:\n",
    "- **True Positives:** 310 instances were labeled correctly as Urgup Sivrisi.\n",
    "- **True Negatives:** 305 instances were labeled correctly as Cercevelik.\n",
    "- **False Negatives:** 61 instances were labeled incorrectly as Cercevelik.\n",
    "- **False Positives:** 74 instances were labeled incorrectly as Urgup Sivrisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report, we can get the evaluation metrics of the model. We can also get the accuracy of the model by separately calling the `accuracy_score()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(dt_y_test, pumpkin_dt_test_preds, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(dt_y_test, pumpkin_dt_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline default model resulted in a test accuracy of `0.828` for this dataset. We can improve this through hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">*What values to consider for each hyperparameter to tune? What basis*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some regularization techniques for decision trees are deciding on the stopping criterion. We can modify the parameters of the `DecisionTreeClassifier()` model so that our model stops asking questions once it reaches certain thresholds. For this model, we can tune the following parameters: `criterion`, `min_samples_split`, `max_depth`, and `max_leaf_nodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to tune: criterion, min_samples_split, max_depth, max_leaf_nodes\n",
    "# Values considered for hyperparams can still be changed based on related works found\n",
    "hyperparameters = [\n",
    "    {\n",
    "        \"criterion\" : [\"gini\", \"entropy\"],\n",
    "        \"min_samples_split\" : [10,20,50,100,500,1000,2000],\n",
    "        \"max_depth\" : [10,20,50,100,500],\n",
    "        \"max_leaf_nodes\" : [10,20,50,100,500,1000,1500]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the `RandomizedSearchCV()`, we can find the best hyperparameters using cross-validation. Since we've defined our hyperparameter options in the previous cell, we can just input this as our parameter for `param_distributions` using 5-fold cross-validation. <br>\n",
    "*Optionally: explain why RandomizedSearchCV over other search algorithms for determining the best hyperparameters* <br>\n",
    "*Some sources: https://insidelearningmachines.com/tune_hyperparameters_in_decision_trees/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iter: number of parameter settings to be sampled\n",
    "# cv: number of cross validation folds\n",
    "rsc_pumpkin = RandomizedSearchCV(estimator=pumpkin_dt,param_distributions=hyperparameters,n_iter=100,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit our data to this `RandomizedSearchCV` model, and it finds the best parameters for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc_pumpkin.fit(dt_X_train,dt_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the `best_params_` variable, we can get the dictionary of best hyperparameter values for our tuned decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc_pumpkin.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the best hyperparameters based from `RandomizedSearchCV`, we can define a new estimator model based on these hyperparameters. We follow the same pipeline as the baseline model, in which we fit the model using our train data and create predictions on our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_dt_tuned = DecisionTreeClassifier(min_samples_split=100, max_leaf_nodes=10, max_depth=20,criterion=\"gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_dt_tuned.fit(dt_X_train,dt_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_dt_tuned_preds = pumpkin_dt_tuned.predict(dt_X_test)\n",
    "pumpkin_dt_tuned_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the tuned decision tree model and created predictions on our test data, we can describe and visualize this tuned tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_tree(pumpkin_dt_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(pumpkin_dt_tuned)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We significantly ended up with lesser nodes and a more shallow depth of tree. Our tuned tree now has 19 nodes, and at the root node, it looks at the feature at index 6 to ask the first question. This is the same as our original tree, and it asks about the `Eccentricity` of the pumpkin seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 3: Logistic Regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset mainly consists of 2 classes (\"Cercevelik\" and \"Urgup Sivrisi\"), we can use Logistic Regression in predicting the pumpkin seed class based on the provided features.  This is primarily because Logistic Regression excels in binary classification problems.  The dataset's features, including area, perimeter, major axis lengths, and others, provide valuable information for predicting seed class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `sklearn`'s `SGDClassifier` to create our logistic regression model. A binomial logistic regression is optimal for our model since there are only two classes (`Çerçevelik` or `Ürgüp Sivrisi`) in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into 70% for the training set and 30% for the testing set.\n",
    "\n",
    "We will use the normalized data to ensure reliable and efficient SGDClassifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_X_train, logreg_X_test, logreg_y_train, logreg_y_test = train_test_split(X_norm, y, test_size=0.3, random_state=1)\n",
    "print(\"X_train shape : \", logreg_X_train.shape)\n",
    "print(\"y_train shape : \", logreg_y_train.shape)\n",
    "print(\"X_test shape : \", logreg_X_test.shape)\n",
    "print(\"y_test shape : \", logreg_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(logreg_X_train[:, 0], logreg_X_train[:, 1], c=logreg_y_train)\n",
    "plt.title('Train data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(logreg_X_test[:, 0], logreg_X_test[:, 1], c=logreg_y_test)\n",
    "plt.title('Test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `SGDClassifier` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting `SGDClassifier` parameters**\n",
    "\n",
    "| Name                      | Parameter       | Value      | Description                                                                                                                     |\n",
    "|---------------------------|-----------------|------------|---------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Loss function**         | `loss`          | 'log_loss' | Set to `'log_loss'` for logistic regression.                                                                                    |\n",
    "| **Initial learning rate** | `eta0`          | 0.001      | Set the initial learning rate to a small value (`0.001`) to ensure gradual updates, preventing overshooting optimal parameters. |\n",
    "| **Maximum iterations**    | `max_iter`      | 200        | Limit the training iterations to `200` to prevent overfitting.                                                                  |\n",
    "| **Learning rate**         | `learning_rate` | 'constant' | Maintain a constant learning rate throughout training.                                                                          |\n",
    "| **Random state**          | `random_state`  | 1          | Ensure reproducibility by fixing the random seed.                                                                               |\n",
    "| **Verbose**               | `verbose`       | 1          | Display training progress.                                                                                                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = SGDClassifier(\n",
    "    loss='log_loss',\n",
    "    eta0=0.001,\n",
    "    max_iter=200,\n",
    "    learning_rate='constant',\n",
    "    random_state=1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model by calling the `fit()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(logreg_X_train, logreg_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if our model does well, we test our trained model on the test set and get the prediction results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = logreg.predict(logreg_X_test)\n",
    "print(logreg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7** | **Error Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 1: K-Nearest Neighbors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the KNN model. First, let's train the KNN model again, with the same configurations in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "k_choices = range(1, 21)\n",
    "for k in k_choices:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k) # Instantiate\n",
    "    score = cross_val_score(knn, X_train, y_train, cv=10).mean() # Get the avg cross-val accuracy\n",
    "    accuracy_scores.append(score)\n",
    "# Train model with best k\n",
    "best_k = k_choices[np.argmax(accuracy_scores)]\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Çerçevelik is encoded as `0` and Ürgüp Sivrisi as `1`.  \n",
    "<b>True positives:</b> $306$ instances were labeled correctly as Ürgüp Sivrisi.<br>\n",
    "<b>True negatives:</b> $346$ instances were labeled correctly as Çerçevelik.<br>\n",
    "<b>False negatives:</b> $65$ instances were labeled incorrectly as Çerçevelik.<br>\n",
    "<b>False positives:</b> $33$ instances were labeled incorrectly as Ürgüp Sivrisi.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the higher amount of true positives and false negatives, it seems that Ürgüp Sivrisi seeds are harder to classify correctly. Let's get the evaluation metrics per class using `classification_report()`, and then the overall test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN model gives a 0.873 test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 2: Decision Trees*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the confusion matrix of the results of the tuned Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix of the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(dt_y_test, pumpkin_dt_tuned_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Çerçevelik is encoded as `0` and Ürgüp Sivrisi as `1`. The confusion matrix of the tuned tree resulted in the following values:\n",
    "- **True Positives:** 330 instances were labeled correctly as Urgup Sivrisi.\n",
    "- **True Negatives:** 321 instances were labeled correctly as Cercevelik.\n",
    "- **False Negatives:** 41 instances were labeled incorrectly as Cercevelik.\n",
    "- **False Positives:** 58 instances were labeled incorrectly as Urgup Sivrisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report, we can get the evaluation metrics of the tuned model. We can also get its accuracy by separately calling the `accuracy_score()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pumpkin_dt_tuned_preds, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, pumpkin_dt_tuned_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Decision Tree model, the **Çerçevelik** class resulted in a precision of **0.89** and a recall of **0.85**, while the **Ürgüp Sivrisi** class resulted in a precision of **0.85** and a recall of **0.89**.\n",
    "\n",
    "The tuned model resulted in a test accuracy of `0.868` for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 3: Logistic Regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the confusion matrix to evaluate the performance of the Logistic Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(logreg_y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Çerçevelik is encoded as `0` and Ürgüp Sivrisi as `1`. \n",
    "- **True positives**: 301 instances were labeled correctly as Ürgüp Sivrisi\n",
    "- **True negatives**: 335 instances were labeled correctly as Çerçevelik\n",
    "- **False positives**: 44 instances were labeled incorrectly as Ürgüp Sivrisi\n",
    "- **False negatives**: 70 instances were labeled incorrectly as Çerçevelik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the precision, recall, and other evaluation metrics per class using `classification_report()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(logreg_y_test, logreg_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Çerçevelik** class has a precision of **0.83** and a recall of **0.88**, while the **Ürgüp Sivrisi** class has a precision of **0.87** and a recall of **0.81**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the accuracy of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy:\", accuracy_score(logreg_y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression model has an accuracy of **0.848**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8** | **Improving Model Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 1: K-Nearest Neighbors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of KNN, let's use Grid Search to get the best combination of hyperparameters `k`, `weights` and `distance metric`. First, we'll import the needed library for Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set the parameter grid with a slightly increased range of `k`, the distance metrics as `euclidean`, `manhattan`, and `minkowski`, and the weights as `uniform` and `distance`.\n",
    "<ul>\n",
    "<li>k - number of neighbors KNN will consider</li>\n",
    "<li>weights - determines if closer neighbors have more influence</li>\n",
    "<li>distance metric - determines how distance is calculated to consider neighbors</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier() # Instantiate\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': range(1,31), # values for k, slightly increased\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'], # distance metrics\n",
    "    'weights': ['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also perform grid search with slightly more k-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(knn, param_grid, cv=20, scoring='accuracy') # Instantiate\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the results of different hyperparameter configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).sort_values(by=[\"rank_test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the top results, the best hyperparameter configurations are generally:\n",
    "<ul>\n",
    "<li>k - mixed, mostly 12</li>\n",
    "<li>weights - mostly distance</li>\n",
    "<li>distance metric - mixed, but mostly manhattan</li>\n",
    "</ul>\n",
    "Let's get the actual best configuration an cross-validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try using Random Search with similar configurations used in Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(knn, param_grid, n_iter=50, cv=10, random_state=1, scoring='accuracy')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-validation Accuracy:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search has a slightly higher cross-validation accuracy than Random Search so let's use grid search moving forward. Now, we'll test the model with the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = grid_search.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model by printing out some evaluation metrics again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy improved from 0.873 to 0.877."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 2: Decision Trees*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `HistGradientBoostingClassifier` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of `HistGradientBoostingClassifier` using its default parameters.\n",
    "\n",
    "The parameters and its default value can be found in the documentation: https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_boosting = HistGradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "pumpkin_boosting.fit(dt_X_train, dt_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the prediction results on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_boosting_test_preds = pumpkin_boosting.predict(dt_X_test)\n",
    "\n",
    "pumpkin_boosting_test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the evaluation metrics of the model to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(dt_y_test, pumpkin_boosting_test_preds))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(dt_y_test, pumpkin_boosting_test_preds, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(dt_y_test, pumpkin_boosting_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Çerçevelik is encoded as `0` and Ürgüp Sivrisi as `1`. \n",
    "- **True positives**: 326 instances were labeled correctly as Ürgüp Sivrisi\n",
    "- **True negatives**: 341 instances were labeled correctly as Çerçevelik\n",
    "- **False positives**: 38 instances were labeled incorrectly as Ürgüp Sivrisi\n",
    "- **False negatives**: 45 instances were labeled incorrectly as Çerçevelik\n",
    "\n",
    "The **Çerçevelik** class has a precision of **0.88** and a recall of **0.90**, while the **Ürgüp Sivrisi** class has a precision of **0.90** and a recall of **0.88**.\n",
    "\n",
    "The accuracy of the model is `0.8893`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomSearchCV using hyperparameters of DT  \n",
    "*Resources:* https://www.restack.io/p/hyperparameter-tuning-answer-histgradientboostingclassifier-tuning-cat-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the hyperparameters and their ranges for `HistGradientBoostingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_boosting = [\n",
    "    {\n",
    "        \"learning_rate\": [0.01,0.05,0.1],\n",
    "        \"max_iter\": [100, 200, 300, 400, 500],\n",
    "        \"max_depth\": [10,20,50,100,500]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the hyperparameters by performing randomized search (`RandomizedSearchCV`) using 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc_pumpkin_boosting = RandomizedSearchCV(estimator=pumpkin_boosting,param_distributions=hyperparameters_boosting,n_iter=50,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc_pumpkin_boosting.fit(dt_X_train,dt_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best hyperparameters found by the randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc_pumpkin_boosting.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new estimator based on the best hyperparameters found by `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_boosting_tuned = HistGradientBoostingClassifier(max_iter=400,max_depth=10,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_boosting_tuned.fit(dt_X_train,dt_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin_boosting_tuned_preds = pumpkin_boosting_tuned.predict(dt_X_test)\n",
    "\n",
    "pumpkin_boosting_tuned_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(dt_y_test, pumpkin_boosting_tuned_preds))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(dt_y_test, pumpkin_boosting_tuned_preds, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(dt_y_test, pumpkin_boosting_tuned_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy of the tuned HistGradientBoostingClassifier resulted in `0.888`, which does not seem to be much of an improvement as there is only `0.02` difference in accuracy from the actual tuned decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 3: Logistic Regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the parameters of `SGDClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will mainly focus on tweaking the `'eta0'`, `'max_iter'`, and `'learning_rate'` parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible values of each parameter can be found in the documentation:\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the hyperparameters and their ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_params = {\n",
    "    'eta0': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [100, 200, 500],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform hyperparameter tuning using `GridSearchCV`.\n",
    "\n",
    "Set the cross-validation (`cv`) parameter to `10` to improve accuracy by providing more precise estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_gs = GridSearchCV(logreg, logreg_params, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our models on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_gs.fit(logreg_X_train, logreg_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best hyperparameters found by the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best score of the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try conducting hyperparameter tuning using `RandomizedSearchCV` to see if it's better than `GridSearchCV`.\n",
    "\n",
    "We also set the cross-validation (`cv`) to `10`, similar to above.\n",
    "\n",
    "We will set the number of iterations (`n_iter`) parameter to be equal to the number of total possible combinations of hyperparameters.  In this case, since there are $3$ values for `eta0`, $3$ values for `max_iter`, and $4$ values for `learning_rate`, then `n_iter` should be set to $3 \\times 3 \\times 4 = 36$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_rs = RandomizedSearchCV(\n",
    "    logreg,\n",
    "    logreg_params,\n",
    "    n_iter=36,\n",
    "    cv=10,\n",
    "    random_state=1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our models on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_rs.fit(logreg_X_train, logreg_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best hyperparameters found by the randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Print the best score of the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_rs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `GridSearchCV` and `RandomizedSearchCV` both found the same best hyperparameters and both also got the same best score, we will just use the hyperparameters of `GridSearchCV` in making an estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new estimator based on the best hyperparameters found by `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_best = SGDClassifier(\n",
    "    loss='log_loss',\n",
    "    eta0=logreg_rs.best_params_['eta0'],\n",
    "    max_iter=logreg_rs.best_params_['max_iter'],\n",
    "    learning_rate=logreg_rs.best_params_['learning_rate'],\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the estimator on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_best.fit(logreg_X_train, logreg_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the prediction results on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_best_pred = logreg_best.predict(logreg_X_test)\n",
    "print(logreg_best_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the best model by printing the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(logreg_y_test, logreg_best_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(logreg_y_test, logreg_best_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(logreg_y_test, logreg_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison with the initial model, the **accuracy** of the best model increased to `0.864` from `0.848`.\n",
    "\n",
    "The **precision** of the **Cercevelik** class also increased to `0.85` from `0.83`, and the **recall** of the **Urgup Sivrisi** class increased to `0.85` from `0.81`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9** | **Model Performance Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model 1: K-Nearest Neighbors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial model performance was 0.873 while the improved model performance was 0.877. Based on the Grid Search algorithm, the best configurations for KNN are as follows: \n",
    "<ul>\n",
    "<li>k - 12</li>\n",
    "<li>weights - distance</li>\n",
    "<li>distance metric - manhattan</li>\n",
    "</ul>\n",
    "Generally, these configurations help decrease sensitivity to outliers. Distance-based weights increase the influence of closer neighbors while manhattan distance metric avoids amplifying distances, which helps resist outliers, opposite to Euclidean distance which squares the distances.(Nixon & Aguado, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10** | **Insights and Conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pumpkin seeds dataset's Exploratory Data Analysis (EDA) revealed several key insights that significantly impact the model training process. Firstly, features like *'Aspect_Ration', 'Eccentricity', and 'Major_Axis_Length'* demonstrated strong positive correlations with the target class, while *'Compactness', 'Roundness', and 'Minor_Axis_Length'* exhibited strongly negative correlations. This **variation in correlation strengths provided a rationale for selecting these features for model training**, anticipating that they would offer a better predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations for Model Improvement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pumpkin seeds dataset, the EDA revealed features with a **level of uniformity and correlation**, contributing to the similar accuracy achieved by *kNN, Logistic Regression, and Decision Trees*. Additionally, the absence of extreme outliers or skewed distributions allowed these diverse models to capture the essential patterns in the data effectively. This scenario led to a convergence in performance, where even simpler models were as effective as more complex ones in predicting class labels. Consequently, these varied modeling approaches sufficiently interpreted the dataset's structure and feature relationships.\n",
    "\n",
    "The EDA provided invaluable insights into the dataset, guiding feature selection and forming hypotheses about model performance. The combination of EDA, model selection, and hyperparameter tuning was a practical approach, resulting in models that effectively captured the underlying patterns in the data. This comprehensive methodology highlights the importance of thorough exploratory analysis and strategic model optimization in predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11** | **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Koklu, M., Sarigil, S., & Ozbek, O. (2021). The use of machine learning methods in classification\n",
    "of pumpkin seeds (Cucurbita pepo L.). Genetic Resources and Crop Evolution, 68 (7), 2713-2726.\n",
    "Doi: https://doi.org/10.1007/s10722-021-01226-0\n",
    "2. Nixon, M. S., & Aguado, A. S. (2020). Feature extraction and image processing for computer vision (4th ed., pp. 571–604). Elsevier. https://doi.org/10.1016/B978-0-12-814976-8.00012-9\n",
    "3. 3.1. Cross-validation: evaluating estimator performance. (n.d.). Scikit-learn. https://scikit-learn.org/1.5/modules/cross_validation.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
